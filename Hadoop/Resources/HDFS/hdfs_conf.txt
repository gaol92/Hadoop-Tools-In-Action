"D:\Program (X86)\java\jdk1.8.0_111\bin\java" -ea -Didea.test.cyclic.buffer.size=1048576 "-javaagent:D:\Program (X86)\JetBrains\IntelliJ IDEA 2017.2.3\lib\idea_rt.jar=50954:D:\Program (X86)\JetBrains\IntelliJ IDEA 2017.2.3\bin" -Dfile.encoding=UTF-8 -classpath "D:\Program (X86)\JetBrains\IntelliJ IDEA 2017.2.3\lib\idea_rt.jar;D:\Program (X86)\JetBrains\IntelliJ IDEA 2017.2.3\plugins\junit\lib\junit-rt.jar;D:\Program (X86)\JetBrains\IntelliJ IDEA 2017.2.3\plugins\junit\lib\junit5-rt.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\charsets.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\deploy.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\access-bridge-64.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\cldrdata.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\dnsns.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\jaccess.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\jfxrt.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\localedata.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\nashorn.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\sunec.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\sunjce_provider.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\sunmscapi.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\sunpkcs11.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\ext\zipfs.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\javaws.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\jce.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\jfr.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\jfxswt.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\jsse.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\management-agent.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\plugin.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\resources.jar;D:\Program (X86)\java\jdk1.8.0_111\jre\lib\rt.jar;D:\JAVA\IdeaProjects\hadoop\hdfs\out\production\hdfs;D:\Program (X86)\JetBrains\IntelliJ IDEA 2017.2.3\lib\junit-4.12.jar;D:\Program (X86)\JetBrains\IntelliJ IDEA 2017.2.3\lib\hamcrest-core-1.3.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\xz-1.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\asm-3.2.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\avro-1.7.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\gson-2.2.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\junit-4.11.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jsch-0.1.42.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jsp-api-2.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\xmlenc-0.52.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\guava-11.0.2.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jets3t-0.9.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jettison-1.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jetty-6.1.26.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jsr305-1.3.9.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\log4j-1.2.17.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\paranamer-2.3.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\activation-1.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-el-1.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-io-2.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\httpcore-4.2.5.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jaxb-api-2.2.2.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\stax-api-1.0-2.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-cli-1.2.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-net-3.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jersey-core-1.9.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jersey-json-1.9.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\servlet-api-2.5.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\slf4j-api-1.7.5.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\xml-apis-1.3.04.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\zookeeper-3.4.6.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-lang-2.6.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\httpclient-4.2.5.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\xercesImpl-2.9.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-codec-1.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\hadoop-auth-2.6.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\hadoop-hdfs-2.6.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\hamcrest-core-1.3.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\htrace-core-3.0.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jackson-xc-1.9.13.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jaxb-impl-2.2.3-1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jersey-server-1.9.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jetty-util-6.1.26.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\mockito-all-1.8.5.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\netty-3.6.2.Final.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\api-util-1.0.0-M20.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-math3-3.1.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\hadoop-common-2.6.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\java-xmlbuilder-0.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\protobuf-java-2.5.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\slf4j-log4j12-1.7.5.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\snappy-java-1.0.4.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-digester-1.8.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\curator-client-2.6.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jackson-jaxrs-1.9.13.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-daemon-1.0.13.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-logging-1.1.3.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\curator-recipes-2.6.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jasper-runtime-5.5.23.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\api-asn1-api-1.0.0-M20.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-compress-1.4.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-httpclient-3.1.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jasper-compiler-5.5.23.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\apacheds-i18n-2.0.0-M15.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-beanutils-1.7.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\curator-framework-2.6.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jackson-core-asl-1.9.13.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\hadoop-annotations-2.6.4.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-collections-3.2.2.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-configuration-1.6.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\jackson-mapper-asl-1.9.13.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\commons-beanutils-core-1.8.0.jar;D:\JAVA\IdeaProjects\hadoop\hdfs-lib\apacheds-kerberos-codec-2.0.0-M15.jar" com.intellij.rt.execution.junit.JUnitStarter -ideVersion5 -junit4 com.nwnu.hadoop.hdfs.HdfsClientDemo,getConf
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
hadoop.security.groups.cache.secs:300
dfs.datanode.cache.revocation.timeout.ms:900000
dfs.namenode.resource.check.interval:5000
s3.client-write-packet-size:65536
dfs.client.https.need-auth:false
dfs.replication:3
hadoop.security.group.mapping.ldap.directory.search.timeout:10000
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold:10737418240
hadoop.work.around.non.threadsafe.getpwuid:false
fs.ftp.host.port:21
dfs.namenode.avoid.read.stale.datanode:false
dfs.journalnode.rpc-address:0.0.0.0:8485
hadoop.security.kms.client.encrypted.key.cache.expiry:43200000
ipc.client.connection.maxidletime:10000
tfile.io.chunk.size:1048576
fs.automatic.close:true
ha.health-monitor.sleep-after-disconnect.ms:1000
io.map.index.interval:128
dfs.namenode.https-address:0.0.0.0:50470
io.seqfile.sorter.recordlimit:1000000
fs.s3n.multipart.uploads.enabled:false
hadoop.util.hash.type:murmur
dfs.namenode.replication.min:1
dfs.datanode.directoryscan.threads:1
dfs.namenode.fs-limits.min-block-size:1048576
dfs.datanode.directoryscan.interval:21600
fs.AbstractFileSystem.file.impl:org.apache.hadoop.fs.local.LocalFs
dfs.namenode.acls.enabled:false
dfs.client.short.circuit.replica.stale.threshold.ms:1800000
net.topology.script.number.args:100
hadoop.http.authentication.token.validity:36000
fs.s3.block.size:67108864
dfs.namenode.resource.du.reserved:104857600
ha.failover-controller.graceful-fence.rpc-timeout.ms:5000
s3native.bytes-per-checksum:512
dfs.namenode.datanode.registration.ip-hostname-check:true
dfs.namenode.path.based.cache.block.map.allocation.percent:0.25
dfs.namenode.backup.http-address:0.0.0.0:50105
hadoop.security.group.mapping:org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
dfs.namenode.edits.noeditlogchannelflush:false
dfs.datanode.cache.revocation.polling.ms:500
dfs.namenode.audit.loggers:default
hadoop.security.groups.cache.warn.after.ms:5000
io.serializations:org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
dfs.namenode.lazypersist.file.scrub.interval.sec:300
hadoop.security.crypto.buffer.size:8192
dfs.http.policy:HTTP_ONLY
dfs.namenode.replication.interval:3
dfs.namenode.safemode.min.datanodes:0
dfs.client.file-block-storage-locations.num-threads:10
nfs.dump.dir:/tmp/.hdfs-nfs
dfs.namenode.secondary.https-address:0.0.0.0:50091
hadoop.kerberos.kinit.command:kinit
dfs.block.access.token.lifetime:600
dfs.webhdfs.enabled:true
dfs.client.use.datanode.hostname:false
dfs.namenode.delegation.token.max-lifetime:604800000
fs.trash.interval:0
dfs.datanode.drop.cache.behind.writes:false
dfs.namenode.avoid.write.stale.datanode:false
dfs.namenode.num.extra.edits.retained:1000000
s3.blocksize:67108864
ipc.client.connect.max.retries.on.timeouts:45
dfs.datanode.data.dir:file://${hadoop.tmp.dir}/dfs/data
fs.s3.buffer.dir:${hadoop.tmp.dir}/s3
fs.s3n.block.size:67108864
nfs.exports.allowed.hosts:* rw
ha.health-monitor.connect-retry-interval.ms:1000
hadoop.security.instrumentation.requires.admin:false
nfs.rtmax:1048576
dfs.client.mmap.cache.size:256
dfs.datanode.data.dir.perm:700
io.file.buffer.size:4096
dfs.namenode.backup.address:0.0.0.0:50100
dfs.client.datanode-restart.timeout:30
dfs.datanode.readahead.bytes:4193404
dfs.namenode.xattrs.enabled:true
io.mapfile.bloom.size:1048576
ipc.client.connect.retry.interval:1000
dfs.client-write-packet-size:65536
dfs.namenode.checkpoint.txns:1000000
dfs.datanode.bp-ready.timeout:20
hadoop.security.kms.client.authentication.retry-count:1
dfs.client.block.write.retries:3
fs.swift.impl:org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
ha.failover-controller.graceful-fence.connection.retries:1
dfs.namenode.safemode.threshold-pct:0.999f
dfs.cachereport.intervalMsec:10000
hadoop.security.java.secure.random.algorithm:SHA1PRNG
ftp.blocksize:67108864
dfs.namenode.list.cache.directives.num.responses:100
file.stream-buffer-size:4096
dfs.datanode.dns.nameserver:default
dfs.namenode.replication.considerLoad:true
nfs.allow.insecure.ports:true
dfs.namenode.edits.journal-plugin.qjournal:org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
dfs.client.write.exclude.nodes.cache.expiry.interval.millis:600000
dfs.client.mmap.cache.timeout.ms:3600000
ipc.client.idlethreshold:4000
io.skip.checksum.errors:false
ftp.stream-buffer-size:4096
dfs.client.failover.connection.retries.on.timeouts:0
file.blocksize:67108864
ftp.replication:3
dfs.namenode.replication.work.multiplier.per.iteration:2
hadoop.security.authorization:false
hadoop.http.authentication.simple.anonymous.allowed:true
s3native.client-write-packet-size:65536
hadoop.rpc.socket.factory.class.default:org.apache.hadoop.net.StandardSocketFactory
file.bytes-per-checksum:512
dfs.datanode.slow.io.warning.threshold.ms:300
fs.har.impl.disable.cache:true
rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB:org.apache.hadoop.ipc.ProtobufRpcEngine
io.seqfile.lazydecompress:true
dfs.namenode.reject-unresolved-dn-topology-mapping:false
hadoop.common.configuration.version:0.23.0
hadoop.security.authentication:simple
dfs.datanode.drop.cache.behind.reads:false
dfs.image.compression.codec:org.apache.hadoop.io.compress.DefaultCodec
dfs.client.read.shortcircuit.streams.cache.size:256
file.replication:1
dfs.namenode.accesstime.precision:3600000
dfs.namenode.fs-limits.max-xattrs-per-inode:32
dfs.image.transfer.timeout:60000
io.mapfile.bloom.error.rate:0.005
nfs.wtmax:1048576
hadoop.security.kms.client.encrypted.key.cache.size:500
dfs.namenode.edit.log.autoroll.check.interval.ms:300000
fs.s3a.multipart.purge:false
dfs.namenode.support.allow.format:true
hadoop.hdfs.configuration.version:1
hadoop.security.group.mapping.ldap.search.attr.member:member
dfs.secondary.namenode.kerberos.internal.spnego.principal:${dfs.web.authentication.kerberos.principal}
dfs.stream-buffer-size:4096
hadoop.ssl.client.conf:ssl-client.xml
dfs.namenode.invalidate.work.pct.per.iteration:0.32f
fs.s3a.multipart.purge.age:86400
dfs.journalnode.https-address:0.0.0.0:8481
hadoop.security.kms.client.encrypted.key.cache.low-watermark:0.3f
dfs.namenode.max.objects:0
hadoop.user.group.static.mapping.overrides:dr.who=;
dfs.bytes-per-checksum:512
dfs.datanode.max.transfer.threads:4096
dfs.block.access.key.update.interval:600
tfile.fs.input.buffer.size:262144
ha.failover-controller.new-active.rpc-timeout.ms:60000
dfs.client.cached.conn.retry:3
dfs.client.read.shortcircuit:false
hadoop.ssl.hostname.verifier:DEFAULT
dfs.datanode.hdfs-blocks-metadata.enabled:false
dfs.image.transfer.chunksize:65536
hadoop.http.authentication.type:simple
dfs.namenode.list.encryption.zones.num.responses:100
dfs.client.https.keystore.resource:ssl-client.xml
s3native.blocksize:67108864
net.topology.impl:org.apache.hadoop.net.NetworkTopology
dfs.client.failover.sleep.base.millis:500
io.seqfile.compress.blocksize:1000000
dfs.namenode.path.based.cache.refresh.interval.ms:30000
dfs.namenode.decommission.interval:30
dfs.permissions.superusergroup:supergroup
dfs.namenode.fs-limits.max-directory-items:1048576
dfs.ha.log-roll.period:120
ftp.bytes-per-checksum:512
dfs.user.home.dir.prefix:/user
dfs.namenode.checkpoint.edits.dir:${dfs.namenode.checkpoint.dir}
ipc.client.fallback-to-simple-auth-allowed:false
dfs.blockreport.initialDelay:0
dfs.namenode.inotify.max.events.per.rpc:1000
dfs.namenode.safemode.extension:30000
dfs.client.failover.sleep.max.millis:15000
dfs.namenode.delegation.key.update-interval:86400000
hadoop.rpc.protection:authentication
fs.permissions.umask-mode:022
fs.s3.sleepTimeSeconds:10
dfs.namenode.fs-limits.max-xattr-size:16384
ha.health-monitor.rpc-timeout.ms:45000
hadoop.http.staticuser.user:dr.who
dfs.datanode.http.address:0.0.0.0:50075
fs.s3a.connection.maximum:15
fs.s3a.paging.maximum:5000
fs.AbstractFileSystem.viewfs.impl:org.apache.hadoop.fs.viewfs.ViewFs
fs.ftp.host:0.0.0.0
hadoop.http.authentication.kerberos.keytab:${user.home}/hadoop.keytab
fs.s3a.impl:org.apache.hadoop.fs.s3a.S3AFileSystem
hadoop.jetty.logs.serve.aliases:true
dfs.namenode.fs-limits.max-blocks-per-file:1048576
dfs.client.block.write.replace-datanode-on-failure.enable:true
io.compression.codec.bzip2.library:system-native
dfs.namenode.checkpoint.dir:file://${hadoop.tmp.dir}/dfs/namesecondary
dfs.client.use.legacy.blockreader.local:false
ipc.ping.interval:60000
net.topology.node.switch.mapping.impl:org.apache.hadoop.net.ScriptBasedMapping
nfs.mountd.port:4242
dfs.storage.policy.enabled:true
dfs.namenode.list.cache.pools.num.responses:100
fs.df.interval:60000
nfs.server.port:2049
ha.zookeeper.parent-znode:/hadoop-ha
dfs.namenode.num.checkpoints.retained:2
fs.s3a.attempts.maximum:10
s3native.stream-buffer-size:4096
io.seqfile.local.dir:${hadoop.tmp.dir}/io/local
dfs.https.enable:false
fs.s3n.multipart.copy.block.size:5368709120
dfs.encrypt.data.transfer.cipher.key.bitlength:128
dfs.client.mmap.retry.timeout.ms:300000
dfs.datanode.sync.behind.writes:false
hadoop.ssl.keystores.factory.class:org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
dfs.permissions.enabled:true
fs.AbstractFileSystem.hdfs.impl:org.apache.hadoop.fs.Hdfs
dfs.blockreport.split.threshold:1000000
dfs.datanode.balance.bandwidthPerSec:1048576
hadoop.security.random.device.file.path:/dev/urandom
fs.s3.maxRetries:4
hadoop.http.filter.initializers:org.apache.hadoop.http.lib.StaticUserWebFilter
dfs.namenode.stale.datanode.interval:30000
ipc.client.rpc-timeout.ms:0
fs.client.resolve.remote.symlinks:true
dfs.default.chunk.view.size:32768
hadoop.ssl.enabled.protocols:TLSv1
dfs.namenode.handler.count:10
dfs.image.transfer.bandwidthPerSec:0
rpc.metrics.quantile.enable:false
hadoop.ssl.enabled:false
dfs.replication.max:512
dfs.namenode.name.dir:file://${hadoop.tmp.dir}/dfs/name
dfs.datanode.https.address:0.0.0.0:50475
dfs.datanode.failed.volumes.tolerated:0
ipc.client.kill.max:10
ipc.server.listen.queue.size:128
dfs.client.domain.socket.data.traffic:false
dfs.block.access.token.enable:false
dfs.blocksize:134217728
fs.s3a.connection.timeout:5000
file.client-write-packet-size:65536
dfs.datanode.address:0.0.0.0:50010
ha.failover-controller.cli-check.rpc-timeout.ms:20000
ha.zookeeper.acl:world:anyone:rwcda
ipc.client.connect.max.retries:10
dfs.encrypt.data.transfer:false
dfs.namenode.write.stale.datanode.ratio:0.5f
ipc.client.ping:true
dfs.datanode.shared.file.descriptor.paths:/dev/shm,/tmp
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms:60000
hadoop.tmp.dir:/tmp/hadoop-${user.name}
dfs.datanode.handler.count:10
dfs.client.failover.max.attempts:15
dfs.client.read.shortcircuit.streams.cache.expiry.ms:300000
hadoop.ssl.require.client.cert:false
hadoop.security.uid.cache.secs:14400
dfs.client.read.shortcircuit.skip.checksum:false
dfs.namenode.resource.checked.volumes.minimum:1
dfs.namenode.logging.level:info
dfs.namenode.max.extra.edits.segments.retained:10000
dfs.webhdfs.user.provider.user.pattern:^[A-Za-z_][A-Za-z0-9._-]*[$]?$
dfs.client.mmap.enabled:true
dfs.client.file-block-storage-locations.timeout.millis:1000
dfs.datanode.block.id.layout.upgrade.threads:12
dfs.datanode.use.datanode.hostname:false
hadoop.fuse.timer.period:5
dfs.client.context:default
fs.trash.checkpoint.interval:0
dfs.journalnode.http-address:0.0.0.0:8480
dfs.namenode.delegation.token.renew-interval:86400000
ha.health-monitor.check-interval.ms:1000
dfs.namenode.retrycache.heap.percent:0.03f
ipc.client.connect.timeout:20000
dfs.blockreport.intervalMsec:21600000
fs.s3a.multipart.threshold:2147483647
dfs.https.server.keystore.resource:ssl-server.xml
io.map.index.skip:0
io.native.lib.available:true
s3.replication:3
dfs.namenode.kerberos.internal.spnego.principal:${dfs.web.authentication.kerberos.principal}
fs.AbstractFileSystem.har.impl:org.apache.hadoop.fs.HarFs
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads:2
dfs.namenode.decommission.nodes.per.interval:5
fs.s3n.multipart.uploads.block.size:67108864
dfs.image.compress:false
dfs.datanode.dns.interface:default
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction:0.75f
tfile.fs.output.buffer.size:262144
fs.du.interval:600000
dfs.client.failover.connection.retries:0
dfs.namenode.edit.log.autoroll.multiplier.threshold:2.0
hadoop.security.group.mapping.ldap.ssl:false
fs.s3a.buffer.dir:${hadoop.tmp.dir}/s3a
dfs.namenode.checkpoint.check.period:60
fs.defaultFS:hdfs://hadoopmaster:9000
fs.s3a.multipart.size:104857600
dfs.client.slow.io.warning.threshold.ms:30000
dfs.datanode.max.locked.memory:0
dfs.namenode.retrycache.expirytime.millis:600000
hadoop.security.group.mapping.ldap.search.attr.group.name:cn
dfs.client.block.write.replace-datanode-on-failure.best-effort:false
dfs.ha.fencing.ssh.connect-timeout:30000
dfs.namenode.fs-limits.max-component-length:255
dfs.namenode.enable.retrycache:true
dfs.datanode.du.reserved:0
dfs.datanode.ipc.address:0.0.0.0:50020
dfs.namenode.path.based.cache.retry.interval.ms:30000
hadoop.security.crypto.cipher.suite:AES/CTR/NoPadding
dfs.client.block.write.replace-datanode-on-failure.policy:DEFAULT
dfs.namenode.http-address:0.0.0.0:50070
hadoop.security.crypto.codec.classes.aes.ctr.nopadding:org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec
dfs.ha.tail-edits.period:60
hadoop.security.groups.negative-cache.secs:30
hadoop.ssl.server.conf:ssl-server.xml
s3native.replication:3
hadoop.security.group.mapping.ldap.search.filter.group:(objectClass=group)
hadoop.http.authentication.kerberos.principal:HTTP/_HOST@LOCALHOST
dfs.namenode.startup.delay.block.deletion.sec:0
hadoop.security.group.mapping.ldap.search.filter.user:(&(objectClass=user)(sAMAccountName={0}))
dfs.namenode.edits.dir:${dfs.namenode.name.dir}
dfs.namenode.checkpoint.max-retries:3
s3.stream-buffer-size:4096
ftp.client-write-packet-size:65536
dfs.datanode.fsdatasetcache.max.threads.per.volume:4
dfs.namenode.name.dir.restore:false
dfs.heartbeat.interval:3
dfs.namenode.secondary.http-address:0.0.0.0:50090
ha.zookeeper.session-timeout.ms:5000
s3.bytes-per-checksum:512
dfs.support.append:true
fs.s3a.connection.ssl.enabled:true
hadoop.http.authentication.signature.secret.file:${user.home}/hadoop-http-auth-signature-secret
hadoop.fuse.connection.timeout:300
dfs.namenode.checkpoint.period:3600
dfs.ha.automatic-failover.enabled:false

Process finished with exit code 0
